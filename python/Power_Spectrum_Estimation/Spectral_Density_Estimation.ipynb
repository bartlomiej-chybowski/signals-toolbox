{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Density Estimation\n",
    "This notebook contains a demonstration of three different Power Spectrum estimation techniques.  The first two are classical techniques (periodogram and Blackman and Tukey), and the third is a modern non-parametric technique (minimum variance spectral estimation, MVSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "Start by importing the Python libraries that we will require"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.fftpack as spf\n",
    "import scipy.linalg as spl\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define a function that will return true if running in a Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_jupyter():\n",
    "    \"\"\"Return true if running in a Jupyter Notebook\"\"\"\n",
    "    try:\n",
    "        if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User specified parameters\n",
    "\n",
    "The following parameters can be specified.  \n",
    "\n",
    "Parameter | Meaning\n",
    "--------- | -------\n",
    "<code>p</code> | The number of terms in the autocorrelation for the minimum variance spectral estimate (e.g. 256)\n",
    "<code>M</code> | The block size for the periodogram approaches, and maximum delay for the correlogram (e.g. 256)\n",
    "<code>fs</code> | Length of the FFT after zero padding the data blocks (e.g. 2048)\n",
    "<code>f1</code> | Frequency of first tone\n",
    "<code>f2</code> | Frequency of second tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 256\n",
    "M = 256\n",
    "fs = 2048\n",
    "\n",
    "f1 = 99.5 / M\n",
    "f2 = 104 / M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The signal to be analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(0, 100001)\n",
    "x = np.sin(2*np.pi*n*f1) + 0.5*np.sin(2*np.pi*n*f2) + 0.2*np.random.randn(n.size)\n",
    "\n",
    "# For plotting of figures\n",
    "frequency = np.arange(0, fs) / fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions\n",
    "First we define an efficient autocorrelation function that returns the autocorrelation for a limited set of delays.  The algorithm that it implements is described in the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Autocorrelation(x, M):\n",
    "    \"\"\"\n",
    "        Calculate autocorrelation of x with maximum lag M.\n",
    "        \n",
    "        INPUT:\n",
    "            x - vector to be correlated\n",
    "            M - maximum correlation lag\n",
    "        \n",
    "        RETURN:\n",
    "            acf - autocorrelation of x with lag M\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    #### Step 1 - initialise the index to identify the data block\n",
    "    #### We don't need to copy the data block as Matlab can select\n",
    "    #### the block at the call time of the FFT.  i is reserved for\n",
    "    #### sqrt(-1), so call it index instead\n",
    "    index = 0\n",
    "    \n",
    "    #### Step 2 - compute the FFT of x_i(n)\n",
    "    X = sp.fftpack.fft(x[index*(M+1):(index+1)*(M+1)], 2*M+2)\n",
    "\n",
    "    #### Steps 3 to 6 are repeated, accumulating their results in\n",
    "    #### a vector.  We need to initialise the vector first\n",
    "\n",
    "    result = np.zeros(2*M+2)\n",
    "\n",
    "    # It is also helpful to generate the vector of [ 1 -1 1 ... ]\n",
    "\n",
    "    phase_shift = np.power((-1), np.arange(0, 2*M+2))\n",
    "\n",
    "    # Do the repetition until we run out of data\n",
    "    while (True):\n",
    "\n",
    "        #### Step 3 - compute X_i(k)X^*_i(k) and store\n",
    "\n",
    "        result = result + np.multiply(np.conj(X), X).real\n",
    "\n",
    "        #### Step 4 - increment i\n",
    "\n",
    "        index = index + 1\n",
    "\n",
    "        # Check to see if we have used all of the data\n",
    "        if (index*(M+1) > len(x)):\n",
    "            break\n",
    "\n",
    "        #### Step 5 - compute the transform for the next block\n",
    "\n",
    "        if ((index+1)*(M+1) <= len(x)):\n",
    "            nextX = sp.fftpack.fft(x[index*(M+1):(index+1)*(M+1)], 2*M+2)\n",
    "        else:\n",
    "            # We don't always have a full block of data at the end\n",
    "            # of the record, but we still need to process it\n",
    "            nextX = sp.fftpack.fft(x[index*(M+1):], 2*M+2)\n",
    "\n",
    "        #### Step 6 - add in the product of the previous and next\n",
    "        ####          transforms, with the phase shift\n",
    "\n",
    "        result = result + np.multiply(np.multiply(phase_shift, np.conj(X)), nextX)\n",
    "\n",
    "        #### Step 7 - repeat steps 3 to 6 until all of the data\n",
    "        #### has been used.  Before we do this, we need\n",
    "        #### to make X = nextX\n",
    "\n",
    "        X = nextX\n",
    "\n",
    "    #### Step 8 - inverse FFT\n",
    "\n",
    "    time_domain = sp.fftpack.ifft(result, 2*M+2)\n",
    "\n",
    "    #### Step 9 = present only the first M+1 values\n",
    "\n",
    "    acf = np.divide(time_domain[0:M+1], len(x)).real\n",
    "    \n",
    "    return acf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function to produce the plots that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(x, y,\n",
    "                  xlabel='Normalised frequency',\n",
    "                  ylabel='Magnitude (dB)',\n",
    "                  xlim=[0,0.5], ylim=[-20,35], name=''):\n",
    "    \"\"\"\n",
    "       Plot the magnitude of normalised freuqnecy\n",
    "       INPUT:\n",
    "           x  (array-like): The horizontal coordinates of the data points.\n",
    "           y  (array-like): The vertical coordinates of the data points.\n",
    "           xlabel (string): Label for the x-axis\n",
    "           ylabel (string): Label for the y-axis\n",
    "           name   (string): The name used to save figure.\n",
    "    \"\"\"\n",
    "    # Create the plot figure\n",
    "    plt.figure(figsize = (16, 8))\n",
    "    \n",
    "    # Enlarge figure label and axis size\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    \n",
    "    # Plot the frequency\n",
    "    plt.plot(x, y)\n",
    "    \n",
    "    # Tidy up the plot to control axes sizes and labels\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    #plt.xticks(np.linspace(0, 0.1, 11))\n",
    "    \n",
    "    # Save figure in python or ipython system\n",
    "    if not is_jupyter():\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot input sample\n",
    "Plot a sample of the input signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot(x=n[:fs+1], y=x[:fs+1], xlabel='Sample', ylabel='Amplitude',\n",
    "              xlim=[0,fs], ylim=[-2,2], name='Random_signal_sample.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodograms\n",
    "The first technique we will consider are the periodogram approaches.  The basic periodogram computes $$P_{xx}(k) = \\frac{1}{M}\\left|\\sum_{n=0}^{M-1} x(n)e^{-j 2 \\pi k n/M}\\right|^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first M elements and compute the periodogram\n",
    "Px = 20*np.log10(abs(np.fft.fft(x[:M],fs)))-10*np.log10(M)\n",
    "generate_plot(x=frequency, y=Px, name='Periodogram_estimate_1.pdf')\n",
    "\n",
    "# Repeat this for the next M elements\n",
    "Px = 20*np.log10(abs(np.fft.fft(x[M:2*M],fs)))-10*np.log10(M)\n",
    "generate_plot(x=frequency, y=Px, name='Periodogram_estimate_2.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bartlett periodogram\n",
    "The Bartlett periodogram simply averages a set of periodograms like those produced above.  It is written as:\n",
    "$$ P_{xx}^{\\mathrm{B}}(k) = \\frac{1}{K}\\sum_{i=0}^{K-1}{\\left\\{\\frac{1}{M}\\left|\\sum_{n=0}^{M-1}{x(n+iM)e^{-j2\\pi k n/M}}\\right|^2\\right\\}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out how many periodograms we can compute\n",
    "K = np.floor(len(x)/M).astype(int)\n",
    "\n",
    "# Initialise the accumulation of periodograms\n",
    "Px = np.zeros(fs)\n",
    "\n",
    "for idx in range(K):\n",
    "    Px = Px + np.power(abs(np.fft.fft(x[idx*M:(idx+1)*M],fs)),2)/M\n",
    "\n",
    "# Convert to dB\n",
    "Px = 10 * np.log10(Px) - 10*np.log10(K)\n",
    "\n",
    "generate_plot(x=frequency, y=Px, name='Bartlett_periodogram_estimate.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welch periodogram\n",
    "The Welch method is a modification of the Bartlett method.  Each block of data is windowed prior to computing the discrete Fourier transform, and the blocks of taken from the input are overlapping.  Mathematically:\n",
    "$$P_{xx}^{\\mathrm{W}}(k)\\!=\\! \\frac{1}{L}\\!\\sum_{i=0}^{L-1}\\!{\\left\\{\\!\\frac{1}{MU}\\left|\\sum_{n=0}^{M-1}{x(n+iD)w(n)e^{-j2\\pi k n/M}}\\right|^2\\!\\right\\}}$$\n",
    "where $w(n)$ is the window, and $M-D$ is the number of sampes that overlap from one block to the next.  We will start with a 50% overlap, and apply the Hamming window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = M // 2\n",
    "\n",
    "# Find out how many periodograms we can compute\n",
    "L = np.floor((len(x)-M)/D + 1).astype(int)\n",
    "\n",
    "# Define the window\n",
    "w = 0.54 - 0.46 * np.cos(2 * np.pi * np.arange(0,M) / (M-1))\n",
    "\n",
    "# Calculate the power of the window\n",
    "U = np.dot(w,w)/M\n",
    "\n",
    "# Initialise the accumulation of periodograms\n",
    "Px = np.zeros(fs)\n",
    "\n",
    "for idx in range(L):\n",
    "    Px = Px + np.power(abs(np.fft.fft(np.multiply(w,x[idx*D:idx*D+M]),fs)),2)/(M*U)\n",
    "\n",
    "# Convert to dB\n",
    "Px = 10 * np.log10(Px) - 10*np.log10(L)\n",
    "\n",
    "generate_plot(x=frequency, y=Px, name='Welch_periodogram_Hamming.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative windows can also be used, for example, the Hann window.  In this case, the peak sidelobe level is higher than for the Hamming window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window\n",
    "w = 0.5 - 0.5 * np.cos(2 * np.pi * np.arange(0,M) / (M-1))\n",
    "\n",
    "# Calculate the power of the window\n",
    "U = np.dot(w,w)/M\n",
    "\n",
    "# Initialise the accumulation of periodograms\n",
    "Px = np.zeros(fs)\n",
    "\n",
    "for idx in range(L):\n",
    "    Px = Px + np.power(abs(np.fft.fft(np.multiply(w,x[idx*D:idx*D+M]),fs)),2)/(M*U)\n",
    "\n",
    "# Convert to dB\n",
    "Px = 10 * np.log10(Px) - 10*np.log10(L)\n",
    "\n",
    "generate_plot(x=frequency, y=Px, name='Welch_periodogram_Hann.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating for the Blackman window, the wider main lobe is evident in the resulting plot.  The advantage of this window is the much lower sidelobe levels, but with the level of noise in the signal, there is no benefit in using this window instead of the Hamming window.  In fact, the wider main lobe makes this window a worse choice for this particular signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window\n",
    "w = 0.42 - 0.5 * np.cos(2 * np.pi * np.arange(0,M) / (M-1)) \\\n",
    "        + 0.08 * np.cos(4 * np.pi * np.arange(0,M) / (M-1))\n",
    "\n",
    "# Calculate the power of the window\n",
    "U = np.dot(w,w)/M\n",
    "\n",
    "# Initialise the accumulation of periodograms\n",
    "Px = np.zeros(fs)\n",
    "\n",
    "for idx in range(L):\n",
    "    Px = Px + np.power(abs(np.fft.fft(np.multiply(w,x[idx*D:idx*D+M]),fs)),2)/(M*U)\n",
    "\n",
    "# Convert to dB\n",
    "Px = 10 * np.log10(Px) - 10*np.log10(L)\n",
    "\n",
    "generate_plot(x=frequency, y=Px, name='Welch_periodogram_Blackman.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blackman and Tukey\n",
    "The Blackman and Tukey spectral estimate is also called the correlogram.  This is because it is based on the autocorrelation of the input sequence, and then application of the Wiener-Khintchine theorem to obtain a spectral estimate.  Because the autocorrelation estimate is truncated, a window needs to be applied.  The window should have a non-negative frequency transform.\n",
    "\n",
    "The Blackman and Tukey estimate is formed as:\n",
    "$$P_{xx}^{\\mathrm{BT}}(f)=\\sum_{m=-(M-1)}^{M-1} r_{xx}(m) w(m) e^{-j2\\pi f m}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by computing the autocorrelation\n",
    "rxx = Autocorrelation(x = x, M = M)\n",
    "# Mirror it and combine to also represent the negative delays\n",
    "rxx = np.concatenate((np.flip(rxx), rxx[1:]), axis=None)\n",
    "\n",
    "# Define an index for this\n",
    "m = np.arange(-M,M+1)\n",
    "\n",
    "# Define a window - we'll start with the triangular one\n",
    "w = (M - np.abs(m)) / M\n",
    "\n",
    "# Use the Wiener Khintchine relationship\n",
    "Px = 10 * np.log10(np.abs(np.fft.fft(np.multiply(w,rxx),fs)))\n",
    "\n",
    "generate_plot(x=frequency, y=Px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other windows can also be used, for example the Bartlett window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = (M + 1 - np.abs(m)) / (M + 1)\n",
    "\n",
    "# Use the Wiener Khintchine relationship\n",
    "Px = 10 * np.log10(np.abs(np.fft.fft(np.multiply(w,rxx),fs)))\n",
    "\n",
    "generate_plot(x=frequency, y=Px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the Parzen window, which has a more complex specification, but applied in exactly the same way:\n",
    "$$w(n)= \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "     1-6\\left(\\frac{|n-M|}{M+\\frac{1}{2}}\\right)^2+6\\left(\\frac{|n-M|}{M+\\frac{1}{2}}\\right)^3 &; |n-M|\\le M/2 \\\\\n",
    "      2\\left(1-\\frac{|n-M|}{M+\\frac{1}{2}}\\right)^3 &;M/2 < |n-M| \\le M\n",
    "    \\end{array}\\right.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_centre = 1 - 6  * (np.abs(m)/(M+0.5))**2 + 6 * (np.abs(m)/(M+0.5))**3\n",
    "w_outside = 2 * (1-abs(m)/(M+0.5))**3\n",
    "\n",
    "# Compute the switch points\n",
    "lower = M - (M // 2)\n",
    "upper = M + (M // 2)\n",
    "\n",
    "# Now combine them into one window\n",
    "w = w_outside\n",
    "w[lower:upper+1] = w_centre[lower:upper+1]\n",
    "\n",
    "# Now apply it to the autocorrelation, and compute the results\n",
    "Px = 10 * np.log10(np.abs(np.fft.fft(np.multiply(w,rxx),fs)))\n",
    "\n",
    "generate_plot(x=frequency, y=Px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bohman window is defined as:\n",
    "$$w(n)=\\left(1-\\left|\\frac{n}{M}-1\\right|\\right)\\cos\\left(\\pi\\left|\\frac{n}{M}-1\\right|\\right)+\n",
    "      \\frac{1}{\\pi}\\sin\\left(\\pi\\left|\\frac{n}{M}-1\\right|\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.multiply((1 - np.abs(m)/M),np.cos(np.pi*np.abs(m)/M)) + np.sin(np.pi*np.abs(m)/M)/np.pi\n",
    "\n",
    "# Use the Wiener Khintchine relationship\n",
    "Px = 10 * np.log10(np.abs(np.fft.fft(np.multiply(w,rxx),fs)))\n",
    "\n",
    "generate_plot(x=frequency, y=Px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum variance spectral estimation animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the autocorrelation, and create the Toeplitz matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxx = Autocorrelation(x = x, M = p)\n",
    "R = spl.toeplitz(rxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the eigenvalue decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d, v] = spl.eig(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invert the elements of the diagonal matrix, and store as a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps avoids a divide by zero\n",
    "U = np.divide(np.ones(p+1), (abs(d))+np.finfo(float).eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the eigenvectors. <br>\n",
    "The result is a matrix of dimensions fs x p - each eigenvector is transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = abs(np.fft.fft(v.T, fs))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compute the final spectrum by combining the transformed variables and normalising \n",
    "by the length of the correlation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Px_linear = np.divide(p, (np.dot(V.T, U)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the final result in a dB scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Px = 10*np.log10(Px_linear)\n",
    "\n",
    "generate_plot(x=frequency, y=Px, name='Minimum_variance_spectral_estimate.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can produce an animation of the filter responses as the frequency sweeps from 0 to half the sampling frequency. \n",
    "By observing the amplitude of the frequency terms corresponding to the dominant component, the adaptation of the filters to the input signal can be observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  To compute h_opt, we will need the inverse of R\n",
    "Rinv = np.linalg.inv(R)\n",
    "\n",
    "# Define frequencies to be plotted\n",
    "freq_lower = 0.35\n",
    "freq_upper = 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlarge the figure size and label font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.rcParams[\"figure.figsize\"] = (16, 8)\n",
    "pl.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for freq_sample in range(int(np.ceil(freq_lower*fs)), int(np.floor(freq_upper*fs)+1)):\n",
    "\n",
    "    # Define y scale limits\n",
    "    ylim=[-95,10]\n",
    "    \n",
    "    # Find the frequency of the sample we are going to consider\n",
    "    fl = freq_sample / fs\n",
    "\n",
    "    # And compute its phasor terms\n",
    "    E = np.exp(1j*2*np.pi*fl*np.arange(0, p+1))\n",
    "\n",
    "    # Compute the filter coefficients\n",
    "    h = np.dot(np.dot(Rinv, E), (Px_linear[freq_sample])) / p\n",
    "    \n",
    "    # Calculate the frequency response of the filter\n",
    "    H = np.fft.fft(h.T, fs)\n",
    "    \n",
    "    ### Plot it\n",
    "    # Get current axes instance\n",
    "    ax = pl.gca()\n",
    "    # Plot the figure\n",
    "    ax.plot(frequency, 20*np.log10(abs(H)))\n",
    "    # Tidy up the x axis and y axis\n",
    "    ax.set_xlabel('Normalised frequency')\n",
    "    ax.set_xlim([freq_lower, freq_upper])\n",
    "    ax.set_ylabel('Magnitude (dB)')\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xticks(np.linspace(0.35, 0.45, 11))\n",
    "    ax.set_yticks(np.linspace(-90, 10, 11))\n",
    "    ax.set_title('Centre frequency %6.4f' %fl)\n",
    "    \n",
    "    # Circle the frequency response amplitude corresponding \n",
    "    # to the frequencies of interest\n",
    "    \n",
    "    arrowx =(f1-0.35) * 10\n",
    "    arrowy = (20*np.log10(abs(H[int(f1*fs)]))-ylim[0]) / (ylim[1]-ylim[0])\n",
    "    if (arrowx>0.01) and (arrowx<0.99) and (arrowy>0.01) and (arrowy<0.99):\n",
    "        # Create a scale-free ellipse\n",
    "        el1 = matplotlib.patches.Ellipse(xy = (arrowx, arrowy), \n",
    "                                         width = 0.02, height = 0.03,\n",
    "                                         fc = \"none\", ec = \"black\",\n",
    "                                         transform = ax.transAxes) \n",
    "        ax.add_patch(el1)\n",
    "\n",
    "    arrowx = (f2-0.35) * 10\n",
    "    arrowy=(20*np.log10(abs(H[int(f2*fs)]))-ylim[0]) / (ylim[1]-ylim[0])\n",
    "    if (arrowx>0.01) and (arrowx<0.99) and (arrowy>0.01) and (arrowy<0.99):\n",
    "        el2 = matplotlib.patches.Ellipse(xy = (arrowx, arrowy), \n",
    "                                         width = 0.02, height = 0.03,\n",
    "                                         fc = \"none\", ec = \"black\",\n",
    "                                         transform = ax.transAxes)\n",
    "        ax.add_patch(el2)\n",
    "    \n",
    "    arrowx = (fl-0.35) * 10\n",
    "    arrowy = (20*np.log10(abs(H[int(fl*fs)]))-ylim[0]) / (ylim[1]-ylim[0])\n",
    "    if (arrowx>0.01) and (arrowx<0.99) and (arrowy>0.01) and (arrowy<0.99):\n",
    "        # Add the green small square\n",
    "        ell = matplotlib.patches.Rectangle(xy = (arrowx-0.01,arrowy-0.02),\n",
    "                                           width = 0.02, height = 0.04,\n",
    "                                           fc = \"green\", ec = \"black\",\n",
    "                                           alpha = 0.5, transform = ax.transAxes)\n",
    "        ax.add_patch(ell)\n",
    "    \n",
    "    # And pause briefly so that the graph displays on the screen\n",
    "    display.clear_output(wait=True)\n",
    "    pl.pause(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â© The University of Edinburgh: Produced by D. Laurenson, School of Engineering. Initial code conversion by Xing Zixiao."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
